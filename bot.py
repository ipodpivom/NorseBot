import telebot
from telebot import types
import google.generativeai as genai
import os
import time
import requests
import threading
import random
import asyncio
import edge_tts
from flask import Flask, request

# --- –ö–õ–Æ–ß–ò ---
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
HUGGING_FACE_KEY = os.environ.get("HUGGING_FACE_KEY")
YOUR_CHAT_ID = os.environ.get("YOUR_CHAT_ID")

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
genai.configure(api_key=GEMINI_API_KEY)

# !!! –í–†–ï–ú–ï–ù–ù–û: –°—Ç–∞–≤–∏–º —Å–∞–º—É—é –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å, —á—Ç–æ–±—ã –±–æ—Ç –ø—Ä–æ—Å—Ç–æ –∑–∞–ø—É—Å—Ç–∏–ª—Å—è !!!
# –ê –≤ –ª–æ–≥–∞—Ö –º—ã —É–≤–∏–¥–∏–º, –µ—Å—Ç—å –ª–∏ —Ç–∞–º Flash
model = genai.GenerativeModel('gemini-pro') 
bot = telebot.TeleBot(TELEGRAM_TOKEN)

API_URL = "https://router.huggingface.co/hf-inference/models/stabilityai/stable-diffusion-xl-base-1.0"
headers = {"Authorization": f"Bearer {HUGGING_FACE_KEY}"}

# --- –ü–†–û–ú–ü–¢–´ ---
SYSTEM_PROMPT_TOPIC = "–¢—ã ‚Äî —ç—Ä—É–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–Ω–∞—Ç–æ–∫. –ü—Ä–∏–¥—É–º–∞–π –û–î–ù–£ —Ç–µ–º—É –¥–ª—è —Ä–∞—Å—Å–∫–∞–∑–∞."
SYSTEM_PROMPT_TEXT = "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π —Ä–∞—Å—Å–∫–∞–∑ –ø–æ —Ç–µ–º–µ."
SYSTEM_PROMPT_VOICE = "–ù–∞–ø–∏—à–∏ 1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –≤—Å—Ç—É–ø–ª–µ–Ω–∏—è."
SYSTEM_PROMPT_IMAGE = "Epic scene describing: "

def clean_text(text):
    return text.replace("**", "").replace("__", "").replace("##", "").replace("* ", "- ")

def send_long_message(chat_id, text):
    if len(text) > 4000:
        for x in range(0, len(text), 4000):
            bot.send_message(chat_id, text[x:x+4000])
            time.sleep(1)
    else:
        bot.send_message(chat_id, text)

async def generate_voice_file(text, filename):
    communicate = edge_tts.Communicate(text, "ru-RU-DmitryNeural")
    await communicate.save(filename)

def process_topic():
    try:
        # 1. –¢–µ–º–∞
        response_topic = model.generate_content(SYSTEM_PROMPT_TOPIC)
        topic = response_topic.text.strip()
        bot.send_message(YOUR_CHAT_ID, f"‚ú® –¢–µ–º–∞: {topic}")

        # 2. –ö–∞—Ä—Ç–∏–Ω–∫–∞ (–ø–æ–∫–∞ –±–µ–∑ –Ω–µ–π—Ä–æ-–ø—Ä–æ–º–ø—Ç–∞, —á—Ç–æ–±—ã –ø—Ä–æ—â–µ –±—ã–ª–æ)
        response_img = requests.post(API_URL, headers=headers, json={"inputs": f"{SYSTEM_PROMPT_IMAGE} {topic}"})
        if response_img.status_code == 200:
            bot.send_photo(YOUR_CHAT_ID, response_img.content)

        # 3. –ì–æ–ª–æ—Å
        voice_text = model.generate_content(f"{SYSTEM_PROMPT_VOICE} –¢–µ–º–∞: {topic}").text
        filename = f"voice_{random.randint(1,999)}.mp3"
        asyncio.run(generate_voice_file(clean_text(voice_text), filename))
        with open(filename, 'rb') as audio:
            bot.send_voice(YOUR_CHAT_ID, audio)
        os.remove(filename)

        # 4. –¢–µ–∫—Å—Ç
        story = model.generate_content(f"{SYSTEM_PROMPT_TEXT} –¢–µ–º–∞: {topic}").text
        send_long_message(YOUR_CHAT_ID, clean_text(story))

    except Exception as e:
        bot.send_message(YOUR_CHAT_ID, f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {e}")
        print(f"Error: {e}")

@bot.message_handler(commands=['start'])
def start(message):
    bot.send_message(message.chat.id, "–ñ–º–∏ /story")

@bot.message_handler(commands=['story'])
def story(message):
    bot.send_message(message.chat.id, "–ù–∞—á–∏–Ω–∞—é...")
    process_topic()

# --- SERVER ---
server = Flask(__name__)
@server.route("/")
def webhook():
    return "OK", 200

def run_web_server():
    server.run(host="0.0.0.0", port=int(os.environ.get("PORT", 5000)))

if __name__ == "__main__":
    # --- –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ú–û–î–ï–õ–ï–ô ---
    print("üîç –°–ü–ò–°–û–ö –î–û–°–¢–£–ü–ù–´–• –ú–û–î–ï–õ–ï–ô:")
    try:
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                print(f"‚úÖ {m.name}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")
    # ---------------------------

    threading.Thread(target=run_web_server, daemon=True).start()
    print("üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω!")
    bot.infinity_polling()
